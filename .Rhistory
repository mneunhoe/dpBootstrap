function(P_tilde, sample = TRUE) {
n <- round(sum(P_tilde), 0)
# Get counts per bin
if (sample) {
tmp_count <-
rmultinom(1, n, P_tilde)
} else {
tmp_count <- as.matrix(round(P_tilde, 0))
}
synthetic_data <- NULL
for (i in 1:nrow(tmp_count)) {
synthetic_data <-
c(synthetic_data, rep(rownames(tmp_count)[i], tmp_count[i, ]))
}
synthetic_data <-
data.frame(t(sapply(
strsplit(synthetic_data, ""), as.numeric
)))
return(synthetic_data)
}
statistics_of_interest <- function(P_tilde) {
synthetic_data <-
get_synthetic_data_from_noisy_counts(P_tilde, sample = FALSE)
list(
coef = coef(glm(X1 ~ X2 + X3, data = synthetic_data, family = binomial)),
mean = colMeans(synthetic_data)
)
}
library(dpBootstrap)
instantiated_mechanism <- function(data) {
dp_count_mechanism(data, rho = 0.01)
}
result <- dp_bootstrap(data = orig_data, mechanism = instantiated_mechanism,
get_synthetic_data = get_synthetic_data_from_noisy_counts, statistics_of_interest = statistics_of_interest,
B = 1000, store_P_tilde = F, store_P_tilde_tilde = F)
get_results(result)
get_results <- function(cdf_results,
alpha = 0.05,
pivot = FALSE) {
# get point estimates from first run
point_estimates <- cdf_results$theta_tilde
# And quantiles from bootstrap
confidence_intervals <-
vector("list", length = length(point_estimates))
names(confidence_intervals) <- names(point_estimates)
for (n in names(confidence_intervals)) {
tmp <-
sapply(cdf_results$theta_tilde_tilde, function(x)
x[[paste0(n)]])
if (is.null(dim(tmp))) {
res <- quantile(tmp, c(alpha / 2, 1 - alpha / 2))
} else {
res <- apply(tmp, 1, quantile, c(alpha / 2, 1 - alpha / 2))
}
confidence_intervals[[paste0(n)]] <- res
}
if (pivot) {
for (n in names(confidence_intervals)) {
tmp <- confidence_intervals[[paste0(n)]]
if (is.null(dim(tmp))) {
res <- 2 * point_estimates[[n]] - tmp[2:1]
names(res) <- names(res)[2:1]
} else {
res <-
(2 * rbind(
point_estimates$quantiles,
point_estimates$quantiles
) - tmp)[2:1, ]
rownames(res) <- rownames(res)[2:1]
}
confidence_intervals[[paste0(n)]] <- res
}
}
return(
list(
point_estimates = point_estimates,
confidence_intervals = confidence_intervals
)
)
}
get_results(result)
statistics_of_interest(dp_count_mechanism(orig_data, rho = 0.0001))
dp_count_mechanism(orig_data, rho = 0.1)
get_synthetic_data_from_noisy_counts(noisy_counts, sample = F)
coef(glm(y ~ x1 + x2, data = orig_data, family = binomial))
coef(glm(X1 ~ X2 + X3, data = get_synthetic_data_from_noisy_counts(counts, sample = FALSE), family = binomial))
coefs <- NULL
for(i in 1:5000){
coefs <- rbind(coefs, coef(glm(X1 ~ X2 + X3, data = get_synthetic_data_from_noisy_counts(counts, sample = T), family = binomial)))
}
library(MASS)
confint(glm(y ~ x1 + x2, data = orig_data, family = binomial))
apply(coefs, 2, quantile, c(0.025, 0.975))
par(mfrow = c(1, 3))
apply(res, 2, hist)
rbind(c(1, 0, 0), c(1, 0, 1), c(1, 1, 0), c(1, 1, 1))
confint(glm(y ~ x1 + x2, data = orig_data, family = binomial))
get_results(result)
n_pop <- 100
x1 <- rbinom(n_pop, 1, 0.5)
x2 <- rbinom(n_pop, 1, 0.5)
true_coef <- c(-2, 1, 1)
logits <- cbind(1, x1, x2) %*% true_coef
probs <- 1 / (1 + exp(-logits))
y <- rbinom(n_pop, 1, probs)
glm(y ~ x1 + x2, family = binomial)
apply(cbind(y, x1, x2), 1, paste0, collapse = "")
# convert number to binary
number2binary <- function(number, noBits) {
binary_vector <- rev(as.numeric(intToBits(number)))
if (missing(noBits)) {
return(binary_vector)
} else {
binary_vector[-(1:(length(binary_vector) - noBits))]
}
}
# count bins based on vector of bins
count_bins <- function(data, bins, first_step, k) {
table(factor(apply(data, 1, function(x)
paste0(x[(1:k) + first_step], collapse = "")), levels = bins))
}
number2binary(0, 3)
bins <-
apply(sapply(0:7, function(x)
number2binary(x, 3)), 2, paste0, collapse = "")
counts <-
table(factor(apply(cbind(y, x1, x2), 1, paste0, collapse = ""), levels = bins))
gaussian_sd <- function(rho, sensitivity) {
return(sensitivity / sqrt((2 * rho)))
}
gaussian_sd(0.5, 1)
rho <- 0.1
noisy_counts <-
counts + rnorm(length(bins), mean = 0, gaussian_sd(rho, 1))
noisy_counts[noisy_counts < 0] <- 0
tmp_synthetic_data <- NULL
for (bin in 1:length(noisy_counts)) {
tmp_synthetic_data <-
c(tmp_synthetic_data, rep(names(noisy_counts)[bin], noisy_counts[bin]))
}
synthetic_data <-
data.frame(t(sapply(
strsplit(tmp_synthetic_data, ""), as.numeric
)))
colnames(synthetic_data) <- c("y", "x1", "x2")
glm(y ~ x1 + x2, data = synthetic_data, family = binomial)
orig_data <- data.frame(y = y, x1 = x1, x2 = x2)
coef(glm(y ~ x1 + x2, data = orig_data, family = binomial))
logistic_link <- function(x) {
1 / (1 + exp(-x))
}
logistic_link(cbind(1, t(sapply(0:3, function(x)
number2binary(x, 2)))) %*% c(0, 0, 0))
beta <- c(0, 0, 0)
ll <- function(beta, n_x = 2, noisy_counts) {
pre_p <-
logistic_link(cbind(1, t(sapply(0:(2 ^ n_x - 1), function(x)
number2binary(x, n_x)))) %*% beta)
l <-
noisy_counts[5:8] %*% log(pre_p) + noisy_counts[1:4] %*% log(1 - pre_p)
return(-l)
}
res <- NULL
n_c_mat <- NULL
rho <- 0.01
for (i in 1:2000) {
n_c_mat <-
rbind(n_c_mat, counts + round(rnorm(
length(bins), mean = 0, gaussian_sd(rho, 1)
), 0))
}
apply(n_c_mat, 1, function(x)
any(x < 0))
rowSums(n_c_mat)
n_c_mat[n_c_mat < 0] <- 0
for (i in 1:2000) {
res <-
rbind(res, optim(c(0, 0, 0), ll, n_x = 2, noisy_counts = n_c_mat[i, ])$par)
}
cbind(res, apply(n_c_mat, 1, function(x)
any(x < 0)))
apply(res, 2, mean)
apply(res, 2, median)
coef(glm(y ~ x1 + x2, data = orig_data, family = binomial))
a <- runif(10000,-1, 1)
l_a <- logistic_link(a)
plot(
a,
l_a,
pch = 16,
col = viridis::viridis(1, 0.5),
ylim = c(0, 1),
xlim = c(-5, 5)
)
abline(h = c(mean(l_a), median(l_a)), col = 1:2)
abline(v = c(mean(a), median(a)), col = 1:2)
tmp_count <- rmultinom(1, 1000, counts)
as.matrix(round(counts, 0))
data <-orig_data
dp_count_mechanism <-
function(data,
rho = 0.5) {
# This generates a projected dp cdf of the data. All functions are part of the
# dpBootstrap package.
bins <-
apply(sapply(0:(2^(ncol(data))-1), function(x)
number2binary(x, ncol(data))), 2, paste0, collapse = "")
counts <-
table(factor(apply(data, 1, paste0, collapse = ""), levels = bins))
noisy_counts <-
counts + rnorm(length(bins), mean = 0, gaussian_sd(rho, 1))
noisy_counts[noisy_counts < 0] <- 0
return(noisy_counts)
}
get_synthetic_data_from_noisy_counts <-
function(P_tilde, sample = TRUE) {
n <- round(sum(P_tilde), 0)
# Get counts per bin
if (sample) {
tmp_count <-
rmultinom(1, n, P_tilde)
} else {
tmp_count <- as.matrix(round(P_tilde, 0))
}
synthetic_data <- NULL
for (i in 1:nrow(tmp_count)) {
synthetic_data <-
c(synthetic_data, rep(rownames(tmp_count)[i], tmp_count[i, ]))
}
synthetic_data <-
data.frame(t(sapply(
strsplit(synthetic_data, ""), as.numeric
)))
return(synthetic_data)
}
statistics_of_interest <- function(P_tilde) {
synthetic_data <-
get_synthetic_data_from_noisy_counts(P_tilde, sample = FALSE)
list(
coef = coef(glm(X1 ~ X2 + X3, data = synthetic_data, family = binomial)),
mean = colMeans(synthetic_data)
)
}
library(dpBootstrap)
instantiated_mechanism <- function(data) {
dp_count_mechanism(data, rho = 0.01)
}
result <- dp_bootstrap(data = orig_data, mechanism = instantiated_mechanism,
get_synthetic_data = get_synthetic_data_from_noisy_counts, statistics_of_interest = statistics_of_interest,
B = 1000, store_P_tilde = F, store_P_tilde_tilde = F)
get_results(result)
get_results <- function(cdf_results,
alpha = 0.05,
pivot = FALSE) {
# get point estimates from first run
point_estimates <- cdf_results$theta_tilde
# And quantiles from bootstrap
confidence_intervals <-
vector("list", length = length(point_estimates))
names(confidence_intervals) <- names(point_estimates)
for (n in names(confidence_intervals)) {
tmp <-
sapply(cdf_results$theta_tilde_tilde, function(x)
x[[paste0(n)]])
if (is.null(dim(tmp))) {
res <- quantile(tmp, c(alpha / 2, 1 - alpha / 2))
} else {
res <- apply(tmp, 1, quantile, c(alpha / 2, 1 - alpha / 2))
}
confidence_intervals[[paste0(n)]] <- res
}
if (pivot) {
for (n in names(confidence_intervals)) {
tmp <- confidence_intervals[[paste0(n)]]
if (is.null(dim(tmp))) {
res <- 2 * point_estimates[[n]] - tmp[2:1]
names(res) <- names(res)[2:1]
} else {
res <-
(2 * rbind(
point_estimates$quantiles,
point_estimates$quantiles
) - tmp)[2:1, ]
rownames(res) <- rownames(res)[2:1]
}
confidence_intervals[[paste0(n)]] <- res
}
}
return(
list(
point_estimates = point_estimates,
confidence_intervals = confidence_intervals
)
)
}
statistics_of_interest(dp_count_mechanism(orig_data, rho = 0.0001))
dp_count_mechanism(orig_data, rho = 0.1)
get_synthetic_data_from_noisy_counts(noisy_counts, sample = F)
coef(glm(y ~ x1 + x2, data = orig_data, family = binomial))
coef(glm(X1 ~ X2 + X3, data = get_synthetic_data_from_noisy_counts(counts, sample = FALSE), family = binomial))
coefs <- NULL
for(i in 1:5000){
coefs <- rbind(coefs, coef(glm(X1 ~ X2 + X3, data = get_synthetic_data_from_noisy_counts(counts, sample = T), family = binomial)))
}
library(MASS)
confint(glm(y ~ x1 + x2, data = orig_data, family = binomial))
apply(coefs, 2, quantile, c(0.025, 0.975))
n_pop <- 1000
x1 <- rbinom(n_pop, 1, 0.5)
x2 <- rbinom(n_pop, 1, 0.5)
true_coef <- c(-2, 1, 1)
logits <- cbind(1, x1, x2) %*% true_coef
probs <- 1 / (1 + exp(-logits))
y <- rbinom(n_pop, 1, probs)
glm(y ~ x1 + x2, family = binomial)
apply(cbind(y, x1, x2), 1, paste0, collapse = "")
# convert number to binary
number2binary <- function(number, noBits) {
binary_vector <- rev(as.numeric(intToBits(number)))
if (missing(noBits)) {
return(binary_vector)
} else {
binary_vector[-(1:(length(binary_vector) - noBits))]
}
}
# count bins based on vector of bins
count_bins <- function(data, bins, first_step, k) {
table(factor(apply(data, 1, function(x)
paste0(x[(1:k) + first_step], collapse = "")), levels = bins))
}
number2binary(0, 3)
bins <-
apply(sapply(0:7, function(x)
number2binary(x, 3)), 2, paste0, collapse = "")
counts <-
table(factor(apply(cbind(y, x1, x2), 1, paste0, collapse = ""), levels = bins))
gaussian_sd <- function(rho, sensitivity) {
return(sensitivity / sqrt((2 * rho)))
}
gaussian_sd(0.5, 1)
rho <- 0.1
noisy_counts <-
counts + rnorm(length(bins), mean = 0, gaussian_sd(rho, 1))
noisy_counts[noisy_counts < 0] <- 0
tmp_synthetic_data <- NULL
for (bin in 1:length(noisy_counts)) {
tmp_synthetic_data <-
c(tmp_synthetic_data, rep(names(noisy_counts)[bin], noisy_counts[bin]))
}
synthetic_data <-
data.frame(t(sapply(
strsplit(tmp_synthetic_data, ""), as.numeric
)))
colnames(synthetic_data) <- c("y", "x1", "x2")
glm(y ~ x1 + x2, data = synthetic_data, family = binomial)
orig_data <- data.frame(y = y, x1 = x1, x2 = x2)
coef(glm(y ~ x1 + x2, data = orig_data, family = binomial))
logistic_link <- function(x) {
1 / (1 + exp(-x))
}
logistic_link(cbind(1, t(sapply(0:3, function(x)
number2binary(x, 2)))) %*% c(0, 0, 0))
beta <- c(0, 0, 0)
ll <- function(beta, n_x = 2, noisy_counts) {
pre_p <-
logistic_link(cbind(1, t(sapply(0:(2 ^ n_x - 1), function(x)
number2binary(x, n_x)))) %*% beta)
l <-
noisy_counts[5:8] %*% log(pre_p) + noisy_counts[1:4] %*% log(1 - pre_p)
return(-l)
}
res <- NULL
n_c_mat <- NULL
rho <- 0.01
for (i in 1:2000) {
n_c_mat <-
rbind(n_c_mat, counts + round(rnorm(
length(bins), mean = 0, gaussian_sd(rho, 1)
), 0))
}
apply(n_c_mat, 1, function(x)
any(x < 0))
rowSums(n_c_mat)
n_c_mat[n_c_mat < 0] <- 0
for (i in 1:2000) {
res <-
rbind(res, optim(c(0, 0, 0), ll, n_x = 2, noisy_counts = n_c_mat[i, ])$par)
}
cbind(res, apply(n_c_mat, 1, function(x)
any(x < 0)))
apply(res, 2, mean)
apply(res, 2, median)
orig_data <- data.frame(y = y, x1 = x1, x2 = x2)
a <- runif(10000,-1, 1)
coef(glm(y ~ x1 + x2, data = orig_data, family = binomial))
lapply(1:2, function(x) rbinom(100, 1, 0.5))
data.frame(lapply(1:n_features, function(x) rbinom(n, 1, 0.5)))
n_features = 2
n = 1000
data.frame(lapply(1:n_features, function(x) rbinom(n, 1, 0.5)))
sapply(1:n_features, function(x) rbinom(n, 1, 0.5))
tmp <- sapply(1:n_features, function(x) rbinom(n, 1, 0.5))
tmp <- sapply(1:n_features, function(x) rbinom(n, 1, 0.5))
true_coef <- runif(n_features+1, -1, 1)
true_coef
logits <- cbind(1, x1, x2) %*% true_coef
logits <- cbind(1, tmp) %*% true_coef
logits
probs <- 1 / (1 + exp(-logits))
probs
logits <- cbind(1, tmp) %*% true_coef
logits
true_coef
tmp
cbind(1, tmp) %*% true_coef
logits
probs <- 1 / (1 + exp(-logits))
probs
rbinom(n, 1, probs)
y <- rbinom(n, 1, probs)
data.frame(y, tmp)
generate_binary_population <- function(n = 1000, n_features = 2, true_coef = NULL){
if(is.null(true_coef)){
true_coef <- runif(n_features+1, -1, 1)
}
tmp <- sapply(1:n_features, function(x) rbinom(n, 1, 0.5))
logits <- cbind(1, tmp) %*% true_coef
probs <- 1 / (1 + exp(-logits))
y <- rbinom(n, 1, probs)
df <- data.frame(y, tmp)
return(df)
}
generate_binary_population()
generate_binary_population <- function(n = 1000, n_features = 2, true_coef = NULL){
if(is.null(true_coef)){
true_coef <- runif(n_features+1, -1, 1)
}
tmp <- sapply(1:n_features, function(x) rbinom(n, 1, 0.5))
logits <- cbind(1, tmp) %*% true_coef
probs <- 1 / (1 + exp(-logits))
y <- rbinom(n, 1, probs)
df <- data.frame(y, tmp)
return(list(df, true_coef))
}
generate_binary_population()
generate_binary_population(true_coef = c(-2, 1, 1))
?stopifnot
generate_binary_population <- function(n = 1000, n_features = 2, true_coef = NULL){
if(is.null(true_coef)){
true_coef <- runif(n_features+1, -1, 1)
}
stopifnot(length(true_coef) == n_features+1)
tmp <- sapply(1:n_features, function(x) rbinom(n, 1, 0.5))
logits <- cbind(1, tmp) %*% true_coef
probs <- 1 / (1 + exp(-logits))
y <- rbinom(n, 1, probs)
df <- data.frame(y, tmp)
return(list(df, true_coef))
}
generate_binary_population(true_coef = c(-2, 1, 1))
generate_binary_population(true_coef = c(-2, 1))
generate_binary_population <- function(n = 1000, n_features = 2, true_coef = NULL){
if(is.null(true_coef)){
true_coef <- runif(n_features+1, -1, 1)
}
stopifnot("Number of coefficeints and features must match" = length(true_coef) == n_features+1)
tmp <- sapply(1:n_features, function(x) rbinom(n, 1, 0.5))
logits <- cbind(1, tmp) %*% true_coef
probs <- 1 / (1 + exp(-logits))
y <- rbinom(n, 1, probs)
df <- data.frame(y, tmp)
return(list(df, true_coef))
}
generate_binary_population(true_coef = c(-2, 1))
generate_binary_population <- function(n = 1000, n_features = 2, true_coef = NULL){
if(is.null(true_coef)){
true_coef <- runif(n_features+1, -1, 1)
}
stopifnot("Number of coefficeints and features must match" = length(true_coef) == n_features+1)
tmp <- sapply(1:n_features, function(x) rbinom(n, 1, 0.5))
logits <- cbind(1, tmp) %*% true_coef
probs <- 1 / (1 + exp(-logits))
y <- rbinom(n, 1, probs)
df <- data.frame(y, tmp)
return(list(data = df, true_coef = true_coef))
}
generate_binary_population(true_coef = c(-2, 1, 1))$data
glm(y ~ ., data = generate_binary_population(true_coef = c(-2, 1, 1))$data, family = binomial)
glm(y ~ ., data = generate_binary_population(true_coef = c(-2, 1, 1))$data, family = binomial)
glm(y ~ ., data = generate_binary_population(true_coef = c(-2, 1, 1))$data, family = binomial)
glm(y ~ ., data = generate_binary_population(true_coef = c(-2, 1, 1))$data, family = binomial)
glm(y ~ ., data = generate_binary_population(n = 100,true_coef = c(-2, 1, 1))$data, family = binomial)
glm(y ~ ., data = generate_binary_population(n = 100,true_coef = c(-2, 1, 1))$data, family = binomial)
glm(y ~ ., data = generate_binary_population(n = 100,true_coef = c(-2, 1, 1))$data, family = binomial)
glm(y ~ ., data = generate_binary_population(n = 10000,true_coef = c(-2, 1, 1))$data, family = binomial)
glm(y ~ ., data = generate_binary_population(n = 10000,true_coef = c(-2, 1, 1))$data, family = binomial)
glm(y ~ ., data = generate_binary_population(n = 10000,true_coef = c(-2, 1, 1))$data, family = binomial)
glm(y ~ ., data = generate_binary_population(n = 10000,true_coef = c(-2, 1, 1))$data, family = binomial)
set.seed(1)
glm(y ~ ., data = generate_binary_population(n = 10000,true_coef = c(-2, 1, 1))$data, family = binomial)
set.seed(1)
glm(y ~ ., data = generate_binary_population(n = 10000,true_coef = c(-2, 1, 1))$data, family = binomial)
set.seed(1)
glm(y ~ ., data = generate_binary_population(n = 10000,true_coef = c(-2, 1, 1))$data, family = binomial)
set.seed(1)
glm(y ~ ., data = generate_binary_population(n = 10000,true_coef = c(-2, 1, 1))$data, family = binomial)
set.seed(1)
glm(y ~ ., data = generate_binary_population(n = 10000,true_coef = c(-2, 1, 1))$data, family = binomial)
set.seed(1)
glm(y ~ ., data = generate_binary_population(n = 10000,true_coef = c(-2, 1, 1))$data, family = binomial)
set.seed(1)
glm(y ~ ., data = generate_binary_population(n = 10000,true_coef = c(-2, 1, 1))$data, family = binomial)
